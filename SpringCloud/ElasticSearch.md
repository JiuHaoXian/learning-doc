### Es常见分词器？

[ElasticSearch最全分词器比较及使用方法_赵英超的博客-CSDN博客](https://blog.csdn.net/ZYC88888/article/details/83620572)

##### standard 分词器

英文的处理能力同于StopAnalyzer.支持中文采用的方法为单字切分。他会将词汇单元转换成小写形式，并去除停用词和标点符号。

##### simple 分词器

功能强于WhitespaceAnalyzer, 首先会通过非字母字符来分割文本信息，然后将词汇单元统一为小写形式。该分析器会去掉数字类型的字符。

##### Whitespace 分词器

仅仅是去除空格，对字符没有lowcase化,不支持中文； 并且不对生成的词汇单元进行其他的规范化处理。

##### Stop 分词器

StopAnalyzer的功能超越了SimpleAnalyzer，在SimpleAnalyzer的基础上增加了去除英文中的常用单词（如the，a等），也可以更加自己的需要设置常用单词；不支持中文

##### ==keyword 分词器==

KeywordAnalyzer把整个输入作为一个单独词汇单元，方便特殊类型的文本进行索引和检索。针对邮政编码，地址等文本信息使用关键词分词器进行索引项建立非常方便。



##### 结巴中文分词

特点：

1、支持三种分词模式：

精确模式，试图将句子最精确地切开，适合文本分析；
全模式，把句子中所有的可以成词的词语都扫描出来, 速度非常快，但是不能解决歧义；
搜索引擎模式，在精确模式的基础上，对长词再次切分，提高召回率，适合用于搜索引擎分词。
2、支持繁体分词

3、支持自定义词典

##### THULAC

##### NLPIR

##### ansj分词器

##### 哈工大的LTP